{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/wangjingwen/Documents/GitHub/is6941-ml-social-media/analysis/data/cleaned_BV1dZwLeKEzG_comments.csv\"  # 数据路径\n",
    "STOPWORD_PATH = \"/Users/wangjingwen/Documents/GitHub/is6941-ml-social-media/analysis/data/hit_stopwords.txt\"          # 哈工大停用词表路径\n",
    "SENTIMENT_DICT = {\n",
    "    'pos': 'hownet_positive.txt',           # 积极词典\n",
    "    'neg': 'hownet_negative.txt',           # 消极词典\n",
    "    'level': 'degree_level.txt',            # 程度副词\n",
    "    'deny': 'deny_words.txt'                # 否定词\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= 预处理模块 =================\n",
    "def preprocess(text):\n",
    "    \"\"\"文本预处理函数\"\"\"\n",
    "    # 去除特殊符号和数字\n",
    "    text = re.sub(r'[^\\w\\s\\u4e00-\\u9fa5]', '', text)\n",
    "    # 分词处理\n",
    "    words = jieba.lcut(text)\n",
    "    # 加载停用词表\n",
    "    with open(STOPWORD_PATH, 'r', encoding='utf-8') as f:\n",
    "        stopwords = set([line.strip() for line in f])\n",
    "    # 过滤停用词\n",
    "    return [w for w in words if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= 情感词典加载 =================\n",
    "def load_sentiment_resources():\n",
    "    \"\"\"加载所有情感词典资源\"\"\"\n",
    "    resources = {}\n",
    "    # 加载情感词\n",
    "    for key in ['pos', 'neg']:\n",
    "        with open(SENTIMENT_DICT[key], 'r', encoding='utf-8') as f:\n",
    "            resources[key] = set(line.strip().split('\\t')[0] for line in f if line.strip())\n",
    "    \n",
    "    # 加载程度副词（格式：词语\\t权重）\n",
    "    resources['degree'] = {}\n",
    "    with open(SENTIMENT_DICT['level'], 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                word, score = line.strip().split('\\t')\n",
    "                resources['degree'][word] = float(score)\n",
    "    \n",
    "    # 加载否定词\n",
    "    with open(SENTIMENT_DICT['deny'], 'r', encoding='utf-8') as f:\n",
    "        resources['deny'] = set(line.strip() for line in f if line.strip())\n",
    "    \n",
    "    return resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= 情感分析核心 =================\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.resources = load_sentiment_resources()\n",
    "        self.window_size = 3  # 否定词/程度词的影响窗口\n",
    "    \n",
    "    def analyze_sentence(self, words):\n",
    "        \"\"\"分析单条评论情感值\"\"\"\n",
    "        sentiment_score = 0\n",
    "        # 记录前序修饰词位置\n",
    "        modifiers = defaultdict(list)\n",
    "        \n",
    "        for index, word in enumerate(words):\n",
    "            # 识别否定词\n",
    "            if word in self.resources['deny']:\n",
    "                for i in range(index+1, min(index+self.window_size, len(words))):\n",
    "                    modifiers[i].append('deny')\n",
    "            \n",
    "            # 识别程度副词\n",
    "            if word in self.resources['degree']:\n",
    "                for i in range(index+1, min(index+self.window_size, len(words))):\n",
    "                    modifiers[i].append(('degree', self.resources['degree'][word]))\n",
    "        \n",
    "        # 计算情感值\n",
    "        for index, word in enumerate(words):\n",
    "            current_score = 0\n",
    "            # 判断情感词\n",
    "            if word in self.resources['pos']:\n",
    "                current_score = 1\n",
    "            elif word in self.resources['neg']:\n",
    "                current_score = -1\n",
    "            \n",
    "            # 应用修饰词\n",
    "            for mod in modifiers.get(index, []):\n",
    "                if mod == 'deny':\n",
    "                    current_score *= -1\n",
    "                elif isinstance(mod, tuple) and mod[0] == 'degree':\n",
    "                    current_score *= mod[1]\n",
    "            \n",
    "            sentiment_score += current_score\n",
    "        \n",
    "        return sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hownet_positive.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m comments = df[\u001b[33m'\u001b[39m\u001b[33m评论内容\u001b[39m\u001b[33m'\u001b[39m].tolist()\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 初始化分析器\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m analyzer = \u001b[43mSentimentAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 执行分析\u001b[39;00m\n\u001b[32m     11\u001b[39m results = []\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mSentimentAnalyzer.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28mself\u001b[39m.resources = \u001b[43mload_sentiment_resources\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mself\u001b[39m.window_size = \u001b[32m3\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mload_sentiment_resources\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 加载情感词\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mpos\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mneg\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSENTIMENT_DICT\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      8\u001b[39m         resources[key] = \u001b[38;5;28mset\u001b[39m(line.strip().split(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f \u001b[38;5;28;01mif\u001b[39;00m line.strip())\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 加载程度副词（格式：词语\\t权重）\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/IS6941/lib/python3.11/site-packages/IPython/core/interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'hownet_positive.txt'"
     ]
    }
   ],
   "source": [
    "# ================= 主流程 =================\n",
    "if __name__ == \"__main__\":\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    comments = df['评论内容'].tolist()\n",
    "    \n",
    "    # 初始化分析器\n",
    "    analyzer = SentimentAnalyzer()\n",
    "    \n",
    "    # 执行分析\n",
    "    results = []\n",
    "    for comment in comments:\n",
    "        words = preprocess(comment)\n",
    "        score = analyzer.analyze_sentence(words)\n",
    "        # 分类逻辑\n",
    "        if score >= 0.3:\n",
    "            sentiment = '积极'\n",
    "        elif score <= -0.3:\n",
    "            sentiment = '消极'\n",
    "        else:\n",
    "            sentiment = '中性'\n",
    "        results.append(sentiment)\n",
    "    \n",
    "    # 统计结果\n",
    "    count = pd.Series(results).value_counts()\n",
    "    \n",
    "    # 可视化\n",
    "    plt.figure(figsize=(10,6))\n",
    "    colors = ['#66b3ff','#99ff99','#ff9999']\n",
    "    explode = (0.05, 0, 0)\n",
    "    \n",
    "    plt.pie(count.values,\n",
    "            labels=count.index,\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90,\n",
    "            colors=colors,\n",
    "            explode=explode,\n",
    "            shadow=True)\n",
    "    \n",
    "    plt.title('用户评论情感分布 (n={})'.format(len(comments)), fontsize=14)\n",
    "    plt.axis('equal')\n",
    "    plt.savefig('sentiment_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IS6941",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
