import pandas as pd
import jieba
import re
from collections import defaultdict

# ä¸“ç”¨æœ¯è¯­é¢„å¤„ç†
anime_terms = [
    'æ˜¥æ—¥å½±', 'mygo', 'mujica', 'soyo', 'ç¥¥å­', 'crychic', 
    'ave mujica', 'æ¯é¸¡å¡', 'ç¯', 'ç«‹å¸Œ', 'æ˜¥æ—¥å½±äº‹å˜'
]
for term in anime_terms:
    jieba.add_word(term)

# å¢å¼ºæƒ…æ„Ÿè§„åˆ™
sentiment_rules = {
    'positive': {
        'keywords': {
            'å¥½å¬', 'æ„ŸåŠ¨', 'æ”¯æŒ', 'è¿›æ­¥', 'ç¾å¥½', 'ç¥æ›²', 'å–œæ¬¢', 'å¤©æ‰',
            'æœªæ¥å¯æœŸ', 'æ‹¼å‘½', 'åŠªåŠ›', 'çˆ½', 'é¿é£æ¸¯', 'å’Œè§£', 'åšå®', 'å¹³æ»‘',
            'æ¼”å¥æ˜¥æ—¥å½±', 'æœ‰æ„Ÿè§‰', 'è±ªåº­', 'æ„ŸæŸ“åŠ›', 'å†°', 'ä¸Šå¤´', 'ä¸Šç˜¾'
        },
        'emojis': {'ğŸ˜­', 'ğŸ˜', 'ğŸ¸', 'ğŸ™ğŸ»', 'ğŸ˜‡', 'â˜ï¸', 'ğŸ¤“', 'ğŸ˜‚'}
    },
    'negative': {
        'keywords': {
            'ç ´é˜²', 'çŒå¥‡', 'ä½ä¿—', 'ç¾éš¾', 'ç—›è‹¦', 'èƒŒå›', 'è¿‡å®¶å®¶', 'é”™è¯¯',
            'å“äºº', 'è­¦å‘Š', 'åˆ‡å‰²', 'å´©å', 'å“­', 'åäº†', 'é€†å¤©', 'ç›’', 'æœ¨æŸœå­'
        },
        'emojis': {'ğŸ¤®', 'ğŸ˜‘'}
    },
    'neutral': {
        'keywords': {
            'æ‰“å¡', 'å»ºè®®', 'é”®ç›˜', 'å‰ä»–', 'æ¢—', 'ç©æ¢—', 
            'è·¯äºº', 'åˆ†æ', 'ä»€ä¹ˆæ—¶å€™', 'å‰§æƒ…', 'è½¬ç”Ÿ', 'è¡¥ç•ª'
        },
        'emojis': {'ğŸ¤”', 'ğŸ¹', 'ğŸ’”', 'ğŸ˜¡', 'ğŸ˜¨'}
    }
}

# ç‰¹æ®Šå¥å¼æ¨¡å¼ 
patterns = {
    'positive': [
        r'å¤ªå–œæ¬¢äº†', r'æœªæ¥å¯æœŸ', r'å“­çš„ä¸èƒ½è‡ªå·±', r'æ‹¼å‘½',
        r'å’Œè§£', r'ä¸ºä»€ä¹ˆè¦æ¼”å¥', r'é•¿æœŸç´ é£Ÿ', r'soyo',
        r'å…¨ä½“èµ·ç«‹', r'ä½•æ—¶æ¥çš„', r'æœ±å…ƒç’‹'
    ],
    'negative': [
        r'åˆ‡å‰².*mujica', r'ç ´é˜²', r'è­¦å‘Š', r'çŒå¥‡',
        r'ä½ä¿—', r'ç¾éš¾', r'è¿‡å®¶å®¶'
    ]
}

class AnimeSentimentAnalyzer:
    def __init__(self):
        self.negation_words = {'ä¸', 'æ²¡', 'æ— ', 'é', 'æœª', 'è«'}
        
    def analyze(self, text):
        # é¢„å¤„ç†
        text = re.sub(r'$$\\w\+?$$', '[è¡¨æƒ…]', text)
        
        # æ¨¡å¼åŒ¹é…
        for pattern in patterns['positive']:
            if re.search(pattern, text):
                return 'æ­£é¢'
        for pattern in patterns['negative']:
            if re.search(pattern, text):
                return 'è´Ÿé¢'
        
        # æƒ…æ„Ÿè®¡åˆ†
        scores = defaultdict(int)
        words = jieba.lcut(text)
        
        for word in words:
            for sentiment, rule in sentiment_rules.items():
                if word in rule['keywords']:
                    scores[sentiment] += 3
                    
        # è¡¨æƒ…ç¬¦å·å¤„ç†
        for emoji in re.findall(r'$$è¡¨æƒ…$$', text):
            for sentiment, rule in sentiment_rules.items():
                if emoji in rule['emojis']:
                    scores[sentiment] += 3
        
        # å¦å®šå¤„ç†
        for i in range(1, len(words)):
            if words[i-1] in self.negation_words and words[i] in {'å¥½', 'å–œæ¬¢', 'å¯¹'}:
                scores['negative'] += 3
                
        # ç‰¹å®šæ¢—å¤„ç†
        if 'ä¸ºä»€ä¹ˆè¦æ¼”å¥æ˜¥æ—¥å½±' in text:
            scores['negative'] -= 2 if 'å¼€å¿ƒ' not in text else -3
        
        if not scores:
            return 'ä¸­æ€§'
            
        # ä¿®æ”¹è¿”å›å€¼éƒ¨åˆ†ï¼Œç»Ÿä¸€è½¬æ¢ä¸ºä¸­æ–‡æ ‡ç­¾
        max_sentiment = max(scores, key=scores.get)
        return {
            'positive': 'æ­£é¢',
            'negative': 'è´Ÿé¢',
            'neutral': 'ä¸­æ€§'
        }[max_sentiment]  # å…³é”®ä¿®æ­£ï¼šå°†è‹±æ–‡é”®æ˜ å°„ä¸ºä¸­æ–‡æ ‡ç­¾

def read_txt_basic(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = [line.strip() for line in f.readlines() if line.strip()]
    return lines

# ä¿®æ”¹åçš„è¾“å‡ºå±•ç¤ºéƒ¨åˆ†
if __name__ == "__main__":
    comments = read_txt_basic("cloud_music/Haruhikage.txt")
    
    analyzer = AnimeSentimentAnalyzer()
    results = []
    
    for comment in comments:
        sentiment = analyzer.analyze(comment)
        results.append({
            'è¯„è®ºå†…å®¹': comment,
            'æƒ…æ„Ÿå€¾å‘': sentiment
        })
    
    df = pd.DataFrame(results)
    
    # ç”Ÿæˆç»Ÿè®¡è¡¨æ ¼
    stats = df['æƒ…æ„Ÿå€¾å‘'].value_counts().reset_index()
    stats.columns = ['æƒ…æ„Ÿç±»å‹', 'æ•°é‡']
    stats['å æ¯”'] = (stats['æ•°é‡'] / len(df)).round(2) * 100  # è®¡ç®—ç™¾åˆ†æ¯”
    
    # æ‰“å°ç¾åŒ–åçš„è¾“å‡º
    print("=== æƒ…æ„Ÿåˆ†æç»“æœç»Ÿè®¡ ===")
    print(stats.to_markdown(index=False, tablefmt="grid", stralign="center"))
    
    print("\n=== ç¤ºä¾‹è¯„è®ºåˆ†æ ===")
    sample_df = df.sample(5, random_state=42)[['è¯„è®ºå†…å®¹', 'æƒ…æ„Ÿå€¾å‘']]
    print(sample_df.to_markdown(index=False, tablefmt="grid", stralign="left"))