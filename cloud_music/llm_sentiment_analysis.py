# -*- coding: utf-8 -*-
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from tqdm import tqdm
import re

class AnimeSentimentAnalyzer:
    def __init__(self):
        # æ¨¡å‹é…ç½®
        self.model_name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # ç‰¹æ®Šå‚æ•°ï¼ˆå…³é”®ä¿®å¤ï¼‰
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_name,
            trust_remote_code=True  # å¿…é¡»æ·»åŠ æ­¤å‚æ•°
        )
        
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            trust_remote_code=True,  # å¿…é¡»æ·»åŠ æ­¤å‚æ•°
            torch_dtype=torch.bfloat16,  # é‡åŒ–ä¼˜åŒ–
            device_map="auto"  # è‡ªåŠ¨è®¾å¤‡åˆ†é…
        ).eval()
        
        # é¢†åŸŸæç¤ºæ¨¡æ¿
        self.prompt_template = """[INST] <<SYS>>
ä½ æ˜¯ä¸€ä¸ªåŠ¨æ¼«éŸ³ä¹è¯„è®ºåˆ†æä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼š
1. è¯†åˆ«è¯„è®ºä¸­çš„ä¸“ä¸šæœ¯è¯­ï¼š{terms}
2. åˆ¤æ–­æƒ…æ„Ÿå€¾å‘ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰
3. ç®€è¦è¯´æ˜ç†ç”±
<</SYS>>

è¯„è®ºå†…å®¹ï¼š{comment} [/INST]
"""
        self.anime_terms = [
            'æ˜¥æ—¥å½±', 'mygo', 'mujica', 'soyo', 'ç¥¥å­', 'crychic', 
            'ave mujica', 'æ¯é¸¡å¡', 'ç¯', 'ç«‹å¸Œ', 'æ˜¥æ—¥å½±äº‹å˜'
        ]

    def preprocess(self, text):
        """æ–‡æœ¬æ¸…æ´—"""
        text = re.sub(r'\$\$\\w\+\?\$\$', '[è¡¨æƒ…]', text)
        return text[:512]  # æ§åˆ¶è¾“å…¥é•¿åº¦

    def analyze(self, text):
        """æ ¸å¿ƒåˆ†ææ–¹æ³•"""
        # é¢„å¤„ç†
        cleaned_text = self.preprocess(text)
        
        # æ„å»ºæç¤ºè¯
        prompt = self.prompt_template.format(
            terms="ã€".join(self.anime_terms),
            comment=cleaned_text
        )
        
        # ç”Ÿæˆé…ç½®
        inputs = self.tokenizer(
            prompt,
            return_tensors="pt"
        ).to(self.model.device)
        
        # ç”Ÿæˆå‚æ•°
        generate_kwargs = {
            "max_new_tokens": 50,
            "do_sample": False,
            "temperature": 0.3,
            "repetition_penalty": 1.1
        }
        
        # æ‰§è¡Œæ¨ç†
        with torch.no_grad():
            outputs = self.model.generate(**inputs, **generate_kwargs)
        
        # è§£æç»“æœ
        response = self.tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)
        
        # æå–æƒ…æ„Ÿæ ‡ç­¾ï¼ˆå…³é”®è§£æé€»è¾‘ï¼‰
        if "æ­£é¢" in response:
            return "æ­£é¢"
        elif "è´Ÿé¢" in response:
            return "è´Ÿé¢"
        else:
            return "ä¸­æ€§"

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = AnimeSentimentAnalyzer()
    
    # æµ‹è¯•è¯„è®º
    test_comments = [
        "æ˜¥æ—¥å½±è¿™é¦–æ›²å­å¤ªç¥äº†ï¼Œå¬å¾—æˆ‘æ³ªæµæ»¡é¢ğŸ˜­",
        "æ¯é¸¡å¡çš„å‰§æƒ…å‘å±•æœ‰ç‚¹è¿·ï¼Œç¼–å‰§åœ¨æƒ³ä»€ä¹ˆï¼Ÿ",
        "ä¸ºä»€ä¹ˆè¦æ¼”å¥æ˜¥æ—¥å½±ï¼è¿™ç®€ç›´æ˜¯ç¾éš¾ï¼"
    ]
    
    # æ‰§è¡Œåˆ†æ
    results = []
    for comment in tqdm(test_comments):
        results.append({
            "è¯„è®º": comment,
            "æƒ…æ„Ÿ": analyzer.analyze(comment)
        })
    
    # æ‰“å°ç»“æœ
    import pandas as pd
    print(pd.DataFrame(results).to_markdown(index=False))